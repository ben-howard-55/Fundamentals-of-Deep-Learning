{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP - Multiclass Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X69Zw4qn-iDS"
      },
      "source": [
        "# Multilayer Perceptron for Multiclass Classification\n",
        "Using the Iris Flowers Multiclass Datset \n",
        "\n",
        "- Problem involves predicting the species of a flower given its measurements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_7-loMN_jqE"
      },
      "source": [
        "### Importing required libs to create Deep Learning Model (tf.keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92OAUMj39RyC"
      },
      "source": [
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCMT5t91-hez"
      },
      "source": [
        "### Loading the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuiLuUAV_ui9",
        "outputId": "f5c8bfad-1226-45eb-d162-b6b860ba8411"
      },
      "source": [
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
        "df = read_csv(path, header=None)\n",
        "print(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0    1    2    3               4\n",
            "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
            "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
            "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
            "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
            "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
            "..   ...  ...  ...  ...             ...\n",
            "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
            "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
            "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
            "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
            "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8abWUthAGVV"
      },
      "source": [
        "### Splitting and formatting data into test and train sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaq8OGAPADk6",
        "outputId": "aa12c249-5a00-4605-8407-a10548933a89"
      },
      "source": [
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "X = X.astype('float32')\n",
        "# encoding the labels\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "#splitting into sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (50, 4) (100,) (50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysn_DYK-_uQW"
      },
      "source": [
        "## 1. Defining the Model\n",
        "Here I am getting the shape of the input and creating 4 layers using ReLU neurons.\n",
        "- An input layer of size n.\n",
        "- A hidden layer connected to input densely of size 10.\n",
        "- A hidden layer connected to previous layer densely of size 8.\n",
        "- A ouput SoftMax layer of size 3 (one node for each class) connected to previous layer Densely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLThs7JnBhkt"
      },
      "source": [
        "# Shape of input to Neural Network\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtENREhfCrBi"
      },
      "source": [
        "## 2. Compile the Model\n",
        "- Here I am using the adam model for optimization.\n",
        "- Sparse Categorical Cross-Entropy is used as it only provides results for the most likely class.\n",
        "- Measuring using accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDi_GJhlCqyW"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoYMrkvCD2SG"
      },
      "source": [
        "## 3. Fitting the Model\n",
        "Training the model using 150 epochs and a batch_size of 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta8WLghaD2xX",
        "outputId": "8cee40d8-4ef6-422b-f496-36706b354dbd"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0743c29310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_pF-LzMENbx"
      },
      "source": [
        "## 4. Testing the Model\n",
        "Testing using the 33% of data.\n",
        "- Trained model had a 94% accuracy on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWJKJMseENl4",
        "outputId": "bb40079e-43a9-4d93-c683-d2aaf45556a4"
      },
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %3f' % acc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.940000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD_iaOrOE81H"
      },
      "source": [
        "## 5. Making Predictions\n",
        "\n",
        "- Output below suggests that the input is of class 0, with a 90% weighting. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2FHVFT5E9HV",
        "outputId": "0acea89b-6836-44f8-9be3-0fec5328a694"
      },
      "source": [
        "row = [5.1, 3.5, 1.4, 0.2]\n",
        "y_hat = model.predict([row])\n",
        "print('Predicted: %s (class=%d)'% (y_hat, argmax(y_hat)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: [[0.9092212  0.08949647 0.00128238]] (class=0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}