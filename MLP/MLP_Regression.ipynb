{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP - Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn6RZ7xHnlhd"
      },
      "source": [
        "# Multilayer Perceptron for Regression\n",
        "Using Housing Data from Boston."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uucID2ilVAk"
      },
      "source": [
        "from numpy import sqrt\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8UQoxWSsFih"
      },
      "source": [
        "Loading the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNX17ckvsHw0",
        "outputId": "51e392df-1194-45a2-92bd-1e4d5a9aa6dd"
      },
      "source": [
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(path, header=None)\n",
        "print(df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1      2   3      4   ...     9     10      11    12    13\n",
            "0    0.00632  18.0   2.31   0  0.538  ...  296.0  15.3  396.90  4.98  24.0\n",
            "1    0.02731   0.0   7.07   0  0.469  ...  242.0  17.8  396.90  9.14  21.6\n",
            "2    0.02729   0.0   7.07   0  0.469  ...  242.0  17.8  392.83  4.03  34.7\n",
            "3    0.03237   0.0   2.18   0  0.458  ...  222.0  18.7  394.63  2.94  33.4\n",
            "4    0.06905   0.0   2.18   0  0.458  ...  222.0  18.7  396.90  5.33  36.2\n",
            "..       ...   ...    ...  ..    ...  ...    ...   ...     ...   ...   ...\n",
            "501  0.06263   0.0  11.93   0  0.573  ...  273.0  21.0  391.99  9.67  22.4\n",
            "502  0.04527   0.0  11.93   0  0.573  ...  273.0  21.0  396.90  9.08  20.6\n",
            "503  0.06076   0.0  11.93   0  0.573  ...  273.0  21.0  396.90  5.64  23.9\n",
            "504  0.10959   0.0  11.93   0  0.573  ...  273.0  21.0  393.45  6.48  22.0\n",
            "505  0.04741   0.0  11.93   0  0.573  ...  273.0  21.0  396.90  7.88  11.9\n",
            "\n",
            "[506 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "860AHa80tNGI"
      },
      "source": [
        "Split data into input and output column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUy_OV7TtMD7",
        "outputId": "3bc7e2ab-7666-496e-b2fb-44162192b20f"
      },
      "source": [
        "X, y = df.values[:, :-1], df.values[:,-1]\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.33)\n",
        "print(train_X.shape, test_X.shape, train_y.shape, test_y.shape)\n",
        "\n",
        "n_features = train_X.shape[1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(339, 13) (167, 13) (339,) (167,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqyLts-ot8Ar"
      },
      "source": [
        "## 1. Defining the Model\n",
        "\n",
        "Four Layer neural Network.\n",
        "1. Input of size 13.\n",
        "2. Two hidden layers. Both using ReLU neurons and he_normalization initilization.\n",
        "3. Output layer of 1, as regression model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2M8Kb8Tt6S2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(\n",
        "    Dense(10, \n",
        "          activation='relu', \n",
        "          kernel_initializer='he_normal',\n",
        "          input_shape=(n_features,)\n",
        "        )\n",
        ")\n",
        "model.add(\n",
        "    Dense(8,\n",
        "          activation='relu',\n",
        "          kernel_initializer='he_normal'\n",
        "          )\n",
        ")\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyIgf0mgvDnS"
      },
      "source": [
        "## 2. Compile the Model\n",
        "Using the Adam optimizer and loss function of mean squared error due to the problem being a regression problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-CkDSzbvIGA"
      },
      "source": [
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeBvFhYZvcfv"
      },
      "source": [
        "## 3. Train the Model\n",
        "Using 150 epochs and a bath size of 32 for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEsiOI-kvczR",
        "outputId": "01b4ddb0-45b9-40ac-eb50-8b7316da2fb0"
      },
      "source": [
        "model.fit(train_X, train_y, epochs=150, batch_size=32, verbose=0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f072beb03d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqFhEM3tv2qm"
      },
      "source": [
        "## 4. Evaluating the Model\n",
        "An Mean Squared Error of ~30 and Root Mean Squared Error of ~5.5 (thousands of dollars) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-atpOM1Lv4bf",
        "outputId": "d53e3eb4-1c4e-44b7-f755-9e3444097d56"
      },
      "source": [
        "error = model.evaluate(test_X, test_y, verbose=0)\n",
        "print(\"MSE: %.3f, RMSE: %.3f\" % (error, sqrt(error)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 29.812, RMSE: 5.460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vyazv6iwZCD"
      },
      "source": [
        "## 5. Making a Prediction\n",
        "Units are in thousands.\n",
        "Predicted house price was 30.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwCxY8uuwBUw",
        "outputId": "6e1d91e8-d686-4795-b5bd-07648915315b"
      },
      "source": [
        "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
        "y_hat = model.predict([row])\n",
        "print('predicted: %.3f' % y_hat)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted: 30.513\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}